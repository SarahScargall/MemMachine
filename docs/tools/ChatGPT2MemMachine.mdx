---
title: "ChatGPT2MemMachine"
sidebarTitle: "ChatGPT2MemMachine"
icon: "bolt"
description: "Import chat history from external sources like OpenAI and Locomo into MemMachine."
---

The `chatgpt2memmachine` utility is a Python-based migration tool that transforms exported chat histories into episodic or semantic memories within your MemMachine organization.

<Note>
Before starting, ensure you have your `orgId` and `projectId` available from your MemMachine dashboard.
</Note>

## Quick Start

<Steps>
<Step title ="Prepare your Data">
  Export your chat history from **OpenAI** (Settings > Data Controls > Export Data) or locate your **Locomo** history JSON file.
</Step>
<Step title="Install Dependencies">
  Clone the tool from the [official repository](https://github.com/MemMachine/MemMachine) and install required Python packages.
</Step>
<Step title="Run the Migration">
  Execute the script using the `--source` flag matching your data.

  ```bash
  python migration.py -i conversations.json --org-id my-org --project-id my-project --source openai
  ```
</Step>
</Steps>

## Configuration

The migration script supports several arguments to fine-tune how data is ingested.

### Core Arguments

| **Parameter**    | **Type** | **Description**                                              |
| ---------------- | -------- | ------------------------------------------------------------ |
| `-i, --input`    | `FILE`   | **Required.** Path to the input chat history file.           |
| `-s, --source`   | `string` | Source format: `openai` (default) or `locomo`.               |
| `--org-id`       | `ID`     | The MemMachine `orgId`.                                      |
| `--project-id`   | `ID`     | The MemMachine `projectId`.                                  |
| `--memory-types` | `string` | Types to generate: `episodic` (default), `semantic`, or both. |

### Filtering & Logic

| **Parameter** | **Description**                                             |
| ------------- | ----------------------------------------------------------- |
| `--since`     | Only process messages after a specific date (`YYYY-MM-DD`). |
| `-l, --limit` | Max messages to process per conversation.                   |
| `--user-only` | Exclude assistant responses; only ingest user prompts.      |
| `--dry-run`   | Preview the migration without writing to the API.           |

------

## Advanced Operations

### Resuming Failed Jobs

If a large migration is interrupted, use the `run-id` generated in the `output/` directory to pick up where you left off.

```bash
python migration.py -i chat.json --org-id my-org --project-id my-project \
  --run-id 20260212T1133 --resume
```

### Performance Tuning

For large datasets, use parallel processing to speed up the ingestion:

<Tip>Start with `--workers 4` to balance speed without hitting rate limits on your local MemMachine instance.</Tip>

```bash
python migration.py -i chat.json --org-id my-org --project-id my-project --workers 4
```

------

## Output & Logs

Every execution creates a timestamped run in the `output/` directory:

- `success_{run_id}.txt`: List of migrated message IDs.
- `errors_{run_id}.txt`: Detailed failure logs for debugging.
- `migration_stats_{run_id}.json`: Final count of messages and duration.

## Verifying Your Migration

Once the script completes, you can verify that your memories were correctly ingested by checking the following:

<Steps>
<Step title="Check the Output Files">
The script generates a `migration_stats_{run_id}.json` file in the `output/` directory. Open it to confirm:
* `total_messages_processed` matches your expectations.
* `success_count` represents the majority of your data.
</Step>
<Step title="Spot-Check the API">
You can query your MemMachine instance directly to see if the new memories appear in your project.

```bash
# Example: List the last 5 episodic memories added
curl -X GET "http://localhost:8080/v1/orgs/{orgId}/projects/{projectId}/memories?limit=5&type=episodic"
```
</Step>
<Step title="Review the Trace (Optional)">

If things look off, check `trace_{run_id}.txt`. This file contains the raw API responses for every message, which is the "Source of Truth" if a specific conversation didn't migrate.
</Step>
</Steps>
